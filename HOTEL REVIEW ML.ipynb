{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35b18465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pickle\n",
    "\n",
    "# Import scikit-learn tools, vectorizers, transformer, and classifiers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# import CountVectorizer and TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# import Multinomial Naive Bayes classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# import Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# import Logistic Regression CV Classifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "# import LinearSVC classifier\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4594dcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in data\n",
    "with open('dfML.pickle', 'rb') as b:\n",
    "    df = pickle.load(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1592d062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>clean_text_stem</th>\n",
       "      <th>clean_text_lem</th>\n",
       "      <th>word_count</th>\n",
       "      <th>clean_title_stem</th>\n",
       "      <th>clean_title_lem</th>\n",
       "      <th>word_count_title</th>\n",
       "      <th>...</th>\n",
       "      <th>word_yell</th>\n",
       "      <th>word_yes</th>\n",
       "      <th>word_yet</th>\n",
       "      <th>word_yogurt</th>\n",
       "      <th>word_york</th>\n",
       "      <th>word_you</th>\n",
       "      <th>word_young</th>\n",
       "      <th>word_zero</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Hampton Inn Suites National HarborAlexandria Area</td>\n",
       "      <td>positive</td>\n",
       "      <td>Hotel is in the perfect spot at the perfect pr...</td>\n",
       "      <td>THE DC TRIP</td>\n",
       "      <td>hotel perfect spot perfect price not perfect v...</td>\n",
       "      <td>hotel perfect spot perfect price not perfect v...</td>\n",
       "      <td>277</td>\n",
       "      <td>dc trip</td>\n",
       "      <td>dc trip</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250893</td>\n",
       "      <td>0.458185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Hampton Inn Suites National HarborAlexandria Area</td>\n",
       "      <td>positive</td>\n",
       "      <td>Excellent experience. Will come again and book...</td>\n",
       "      <td>Nice location</td>\n",
       "      <td>excel experience come book stay futur</td>\n",
       "      <td>excellent experience come book stay future</td>\n",
       "      <td>11</td>\n",
       "      <td>nice locat</td>\n",
       "      <td>nice location</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Hampton Inn Suites National HarborAlexandria Area</td>\n",
       "      <td>negative</td>\n",
       "      <td>heat in room did not work properly, tv remote ...</td>\n",
       "      <td>Hampton Inn</td>\n",
       "      <td>heat room not work properly tv remot wa broken...</td>\n",
       "      <td>heat room not work properly tv remote break ex...</td>\n",
       "      <td>13</td>\n",
       "      <td>hampton inn</td>\n",
       "      <td>hampton inn</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Hampton Inn Suites National HarborAlexandria Area</td>\n",
       "      <td>positive</td>\n",
       "      <td>Even though we were having problems, i.e. Feat...</td>\n",
       "      <td>Gracious and helpful staff</td>\n",
       "      <td>even though problems e feather allergy flat ti...</td>\n",
       "      <td>even though problem e feather allergy flat tir...</td>\n",
       "      <td>22</td>\n",
       "      <td>graciou help staff</td>\n",
       "      <td>gracious helpful staff</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.012500</td>\n",
       "      <td>0.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Hampton Inn Suites National HarborAlexandria Area</td>\n",
       "      <td>positive</td>\n",
       "      <td>Brand new hotel in brand new retail area on th...</td>\n",
       "      <td>beautiful, convenient location</td>\n",
       "      <td>brand new hotel brand new retail area water ea...</td>\n",
       "      <td>brand new hotel brand new retail area water ea...</td>\n",
       "      <td>109</td>\n",
       "      <td>beautiful conveni locat</td>\n",
       "      <td>beautiful convenient location</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.178919</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.112746</td>\n",
       "      <td>0.637174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1503 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name    rating  \\\n",
       "28  Hampton Inn Suites National HarborAlexandria Area  positive   \n",
       "29  Hampton Inn Suites National HarborAlexandria Area  positive   \n",
       "30  Hampton Inn Suites National HarborAlexandria Area  negative   \n",
       "31  Hampton Inn Suites National HarborAlexandria Area  positive   \n",
       "32  Hampton Inn Suites National HarborAlexandria Area  positive   \n",
       "\n",
       "                                                 text  \\\n",
       "28  Hotel is in the perfect spot at the perfect pr...   \n",
       "29  Excellent experience. Will come again and book...   \n",
       "30  heat in room did not work properly, tv remote ...   \n",
       "31  Even though we were having problems, i.e. Feat...   \n",
       "32  Brand new hotel in brand new retail area on th...   \n",
       "\n",
       "                             title  \\\n",
       "28                     THE DC TRIP   \n",
       "29                   Nice location   \n",
       "30                     Hampton Inn   \n",
       "31      Gracious and helpful staff   \n",
       "32  beautiful, convenient location   \n",
       "\n",
       "                                      clean_text_stem  \\\n",
       "28  hotel perfect spot perfect price not perfect v...   \n",
       "29              excel experience come book stay futur   \n",
       "30  heat room not work properly tv remot wa broken...   \n",
       "31  even though problems e feather allergy flat ti...   \n",
       "32  brand new hotel brand new retail area water ea...   \n",
       "\n",
       "                                       clean_text_lem  word_count  \\\n",
       "28  hotel perfect spot perfect price not perfect v...         277   \n",
       "29         excellent experience come book stay future          11   \n",
       "30  heat room not work properly tv remote break ex...          13   \n",
       "31  even though problem e feather allergy flat tir...          22   \n",
       "32  brand new hotel brand new retail area water ea...         109   \n",
       "\n",
       "           clean_title_stem                clean_title_lem  word_count_title  \\\n",
       "28                  dc trip                        dc trip                 3   \n",
       "29               nice locat                  nice location                 2   \n",
       "30              hampton inn                    hampton inn                 2   \n",
       "31       graciou help staff         gracious helpful staff                 4   \n",
       "32  beautiful conveni locat  beautiful convenient location                 3   \n",
       "\n",
       "    ...  word_yell word_yes  word_yet  word_yogurt  word_york  word_you  \\\n",
       "28  ...        0.0      0.0       0.0          0.0        0.0  0.000000   \n",
       "29  ...        0.0      0.0       0.0          0.0        0.0  0.000000   \n",
       "30  ...        0.0      0.0       0.0          0.0        0.0  0.000000   \n",
       "31  ...        0.0      0.0       0.0          0.0        0.0  0.000000   \n",
       "32  ...        0.0      0.0       0.0          0.0        0.0  0.178919   \n",
       "\n",
       "    word_young  word_zero  polarity  subjectivity  \n",
       "28         0.0        0.0  0.250893      0.458185  \n",
       "29         0.0        0.0  0.500000      0.562500  \n",
       "30         0.0        0.0 -0.250000      0.533333  \n",
       "31         0.0        0.0 -0.012500      0.562500  \n",
       "32         0.0        0.0  0.112746      0.637174  \n",
       "\n",
       "[5 rows x 1503 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5c381bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3029\n",
       "2     552\n",
       "1     395\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = [\n",
    "    (df['rating'] == 'positive'),\n",
    "    (df['rating'] == 'negative')\n",
    "]\n",
    "rating = [0, 1]\n",
    "df['rating'] = np.select(reviews, rating, default=2)\n",
    "df.rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7c4f5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store tweet dataset into feature matrix and response vector\n",
    "X_words = df['clean_text_lem']\n",
    "y_words = df['rating']\n",
    "\n",
    "# Instantiate CountVectorizer and TfidfVectorizer\n",
    "count_vect = CountVectorizer(min_df=1, ngram_range=(1, 2)) \n",
    "tfidf_vect = TfidfVectorizer(min_df=1, ngram_range=(1, 2))\n",
    "\n",
    "\n",
    "# Apply CountVectorizer \n",
    "X_count = count_vect.fit_transform(df['clean_text_lem'].apply(str))\n",
    "X_count = X_count.tocsc() \n",
    "\n",
    "# Apply TfidfVectorizer\n",
    "X_tfidf = tfidf_vect.fit_transform(df['clean_text_lem'].apply(str))\n",
    "X_tfidf = X_tfidf.tocsc()\n",
    "\n",
    "\n",
    "# Split train/test data for all data\n",
    "Xtrain_count, Xtest_count, ytrain_count, ytest_count = train_test_split(X_count, y_words, random_state=17)\n",
    "Xtrain_tfidf, Xtest_tfidf, ytrain_tfidf, ytest_tfidf = train_test_split(X_tfidf, y_words, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e31efda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(xtest, ytest, clf):\n",
    "    \"\"\" \n",
    "    This function evaluates the effectiveness of a ML model and outputs F1 Scores, AUC score and Confusion Matrix\n",
    "    \"\"\"\n",
    "    # Make predictions for Xtest\n",
    "    y_pred = clf.predict(xtest)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = metrics.confusion_matrix(ytest, y_pred)\n",
    "    \n",
    "    print(classification_report(ytest, y_pred))\n",
    "    print('\\nConfusion Matrix:\\n', cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74d19824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB(alpha=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB(alpha=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB(alpha=1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate multinomialNB()\n",
    "nb_words_count = MultinomialNB(alpha=1, fit_prior=True)\n",
    "nb_words_tfidf = MultinomialNB(alpha=1, fit_prior=True)\n",
    "\n",
    "# Train model\n",
    "nb_words_count.fit(Xtrain_count, ytrain_count)\n",
    "nb_words_tfidf.fit(Xtrain_tfidf, ytrain_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fde2610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.98      0.91       783\n",
      "           1       0.78      0.30      0.43        93\n",
      "           2       0.40      0.17      0.24       118\n",
      "\n",
      "    accuracy                           0.82       994\n",
      "   macro avg       0.68      0.48      0.53       994\n",
      "weighted avg       0.79      0.82      0.79       994\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[770   5   8]\n",
      " [ 43  28  22]\n",
      " [ 95   3  20]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(Xtest_count, ytest_count, nb_words_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c79823e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88       783\n",
      "           1       0.00      0.00      0.00        93\n",
      "           2       0.00      0.00      0.00       118\n",
      "\n",
      "    accuracy                           0.79       994\n",
      "   macro avg       0.26      0.33      0.29       994\n",
      "weighted avg       0.62      0.79      0.69       994\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[783   0   0]\n",
      " [ 93   0   0]\n",
      " [118   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Tanuj\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Tanuj\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Tanuj\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(Xtest_tfidf, ytest_tfidf, nb_words_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "961d10e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and fit training data to Logistic Regression Model (CountVec)\n",
    "log_clf_count = LogisticRegressionCV(scoring='accuracy', \n",
    "                                     class_weight='balanced', \n",
    "                                     cv=5, max_iter=1000).fit(Xtrain_count, ytrain_count)\n",
    "\n",
    "# Instantiate and fit training data to Logistic Regression Model (TFIDF Vec)\n",
    "log_clf_tfidf = LogisticRegressionCV(scoring='accuracy', \n",
    "                                     class_weight='balanced', \n",
    "                                     cv=5, max_iter=1000).fit(Xtrain_tfidf, ytrain_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70ecc2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92       783\n",
      "           1       0.64      0.53      0.58        93\n",
      "           2       0.41      0.27      0.33       118\n",
      "\n",
      "    accuracy                           0.83       994\n",
      "   macro avg       0.65      0.58      0.61       994\n",
      "weighted avg       0.81      0.83      0.82       994\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[747  12  24]\n",
      " [ 22  49  22]\n",
      " [ 70  16  32]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(Xtest_count, ytest_count, log_clf_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f601c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93       783\n",
      "           1       0.65      0.56      0.60        93\n",
      "           2       0.44      0.31      0.36       118\n",
      "\n",
      "    accuracy                           0.84       994\n",
      "   macro avg       0.66      0.61      0.63       994\n",
      "weighted avg       0.82      0.84      0.83       994\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[749  12  22]\n",
      " [ 17  52  24]\n",
      " [ 66  16  36]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(Xtest_tfidf, ytest_tfidf, log_clf_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f256dbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and fit training data to Random Forest Model (CountVec)\n",
    "forest_clf_count = RandomForestClassifier(class_weight='balanced',\n",
    "                                     n_estimators=100).fit(Xtrain_count, ytrain_count)\n",
    "\n",
    "# Instantiate and fit training data to Random Forest Model (TFIDF Vec)\n",
    "forest_clf_tfidf = RandomForestClassifier(class_weight='balanced',\n",
    "                                     n_estimators=100).fit(Xtrain_tfidf, ytrain_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00352179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88       783\n",
      "           1       0.00      0.00      0.00        93\n",
      "           2       0.00      0.00      0.00       118\n",
      "\n",
      "    accuracy                           0.78       994\n",
      "   macro avg       0.26      0.33      0.29       994\n",
      "weighted avg       0.62      0.78      0.69       994\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[780   0   3]\n",
      " [ 93   0   0]\n",
      " [118   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Tanuj\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Tanuj\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Tanuj\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(Xtest_count, ytest_count, forest_clf_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50f8fd0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.99      0.88       783\n",
      "           1       1.00      0.01      0.02        93\n",
      "           2       0.00      0.00      0.00       118\n",
      "\n",
      "    accuracy                           0.78       994\n",
      "   macro avg       0.60      0.33      0.30       994\n",
      "weighted avg       0.71      0.78      0.69       994\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[778   0   5]\n",
      " [ 92   1   0]\n",
      " [118   0   0]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(Xtest_tfidf, ytest_tfidf, forest_clf_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc5d3216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and fit training data to Random Forest Model (CountVec)\n",
    "svc_count = LinearSVC().fit(Xtrain_count, ytrain_count)\n",
    "\n",
    "# Instantiate and fit training data to Random Forest Model (TFIDF Vec)\n",
    "svc_tfidf = LinearSVC().fit(Xtrain_tfidf, ytrain_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c93f2eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91       783\n",
      "           1       0.71      0.48      0.58        93\n",
      "           2       0.42      0.28      0.34       118\n",
      "\n",
      "    accuracy                           0.83       994\n",
      "   macro avg       0.67      0.57      0.61       994\n",
      "weighted avg       0.81      0.83      0.81       994\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[746   9  28]\n",
      " [ 31  45  17]\n",
      " [ 76   9  33]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(Xtest_count, ytest_count, svc_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6cf4e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.77      0.84       783\n",
      "           1       0.36      0.71      0.48        93\n",
      "           2       0.26      0.35      0.29       118\n",
      "\n",
      "    accuracy                           0.72       994\n",
      "   macro avg       0.51      0.61      0.54       994\n",
      "weighted avg       0.80      0.72      0.74       994\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[604  83  96]\n",
      " [  4  66  23]\n",
      " [ 42  35  41]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(Xtest_count, ytest_count, svc_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd724d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
